# Music Interaction Design

*by Guillermo Montecinos, NYU ITP Spring 2019*

This document and the contents stored in this repo corresponds to [Music Interaction Design](https://luisaph.github.io/music-interaction-design-spring-2019/) class taught by Luisa Pereira, at NYU ITP during the 2019 Spring term.

## Week 1

### Music Interaction Exercise
We were expected to design a music interaction based on one musical piece and an oblique strategy. The song I chose is [Sulky](https://www.youtube.com/watch?v=8E-Go310oe4) by the Argentinian musician Gustavo Cerati. Sulky is a 4:18 minutes electro-rock [Chacarera](https://en.wikipedia.org/wiki/Chacarera) –a folk music and dance from the countryside of Río de la Plata zone– written in 6/8 and a tempo of 115 bpm.

This is a song built from samples of typical instruments as Legüero bass drum and guitar, piano and a bunch of synths and unrecognizable samples that conform a dreamlike experience of traveling through a dark and open flat land.

In terms of this exercise, the oblique strategy got was: "Look closely at the most embarrassing details and amplify them". Responding to that, I think this song seeks to prepare the listener through a gentle and dreamlike atmosphere to face –probably– darkness and doubt of life. Darkness and dark feelings are constantly in the back of our heads and we usually are not proud off it. Actually many people avoid to talk and even recognize their darkness. But embracing darkness can make us look inside. So, in this experiment I'd like to design an interaction that –through Sulky– would invite one person to travel through his/her emotions being able to go back and face darkness any time it is needed.

<p align="center">
  <img src="https://github.com/guillemontecinos/itp_spring_2019_music_interaction_design/blob/master/assets/week1_diagram1.jpg" align="middle" width="70%">
</p>

The interaction –for only one person– consists in a dark room with one chair, three screens (one in front of the chair displaying visuals that evoke comfortable feelings and one at each side of it that evoke uncomfortable feelings) and a quadraphonic sound system. The person will be invited to travel through a reconstruction of the song in which the sound layers will be spatialized and synchronized to create a 3D immersion of the listener in the world of light and darkness created by Cerati. As the song plays the listener will be exposed to comfortable visuals displayed in the front screen, but will be tempted to look to his/her side to the uncomfortable visuals that –as our own darkness– will be constantly calling their attention. When the user look to any of the side screens –which means is paying attention to the darkness– the uncomfortable/dark/weird part of the song will be built in real time (played) by the system. For this purpose, the user's head will be tracked with a kinetic sensor placed behind the chair.

<p align="center">
  <img src="https://github.com/guillemontecinos/itp_spring_2019_music_interaction_design/blob/master/assets/week1_diagram2.jpg" align="middle" width="70%">
</p>

### Final Project Iteration /#1

For this project I'm interested in designing an interaction that through music can explore concepts as **identity, community, oppression and migration**, and how these concepts are understood in the post-globalization world were hateful speeches delivered against under represented and discriminated communities have rose. With a southern perspective I'm concerned in engaging territorial and musical communitarian memory, and how that memory can crop up when identity and community are threatened. As well through this interaction I want to challenge the role of technology as a medium used to create interactive installations or applications.

Regarding the kind of this interaction I haven't addressed the final format it will take, but there are some lights. According to [Towards a Dimension Space for Musical Devices](http://lizbeck.net/pdf/nime2005_192.pdf) musical interactions can be parametrized in 7 dimensions that can be plotted in a dimension space chart, these are role of sound, required expertise, musical control, degrees of freedom, feedback modalities, inter-actors and distribution in space. Despite there is no clarity of how will the interaction look like there is certainty that the number of inter-actors can be high because it will be a community-based interaction. As well, the role of sound has to be expressive to engage with community imaginary, and distribution in space –wether physical or virtual– has to be distributed and decentralized. Finally, as this interaction will seek to engage with primal identity aspects of the community there will expected no expertise from the users.

Some references as [Voluspa Jarpa](http://ismorbo.com/voluspa-jarpa-lleva-la-historia-oculta-de-latinoamerica-y-la-cia-al-matucana-100/)

## Week 2
### Final project Iteration /#2
For this iteration of the project I'd like to keep the eye on the concept of community and imagine an interaction around it. According with [Wikipedia](https://en.wikipedia.org/wiki/Community) *A community is a small or large social unit (a group of living things) that has something in common, such as norms, religion, values, or identity* – and usually a sense of territoriality and a common memory as well. The reason why we humans live in communities is because –ideally– together we can make more and better than separated.

Then, a community-based –or communitarian– music interaction can be one that expresses the best of it only when there is an engaged community interacting with it. An interesting goal to approach through this is to connect people around a musical interaction even if they don't know each other –or if they don't have a common memory– and make them realize that the sound landscape they are experiencing exists only because they are they are part of that interaction.

Regarding the above, this interaction can be experienced by any person from any cultural background, so there are no restrictions for play testing.
